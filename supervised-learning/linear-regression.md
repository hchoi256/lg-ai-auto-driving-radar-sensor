****
### Terms
- Linear regression
- Parameter optimization
  - Normal Equation
  - Gradient descent
    - Greedy algorithm

# Linear Regression
![image](https://user-images.githubusercontent.com/39285147/178196382-56e8a8fd-093e-4632-9213-13f6f4ebe595.png)

ì—°ì†ë˜ëŠ” ì¶œë ¥ì„ ì˜ˆì¸¡ì„ í•˜ê³  ì¶”ë¡ í•˜ê¸° ìœ„í•œ ë°©ë²•

## Linear Models
![image](https://user-images.githubusercontent.com/39285147/178196415-38fd2c92-35ea-4e1a-896e-e1735c78019d.png)
![image](https://user-images.githubusercontent.com/39285147/178196701-ce862dc2-fa03-4c3f-a99c-bd71596d1655.png)
- ëª¨ë¸ í•¨ìˆ˜(h)ì— ëŒ€í•´ í”¼ë¼ë¯¸í„°(ì„¸íƒ€)ê°€ ì„ í˜•ì ì¸ ê´€ê³„ì— ìˆë‹¤.
  - ì„ í˜• ëª¨ë¸ì´ë¼ê³  í•´ì„œ ë°˜ë“œì‹œ ì…ë ¥ ë³€ìˆ˜(x)ì— ì„ í˜•ì¼ í•„ìš”ëŠ” ì—†ë‹¤

## Example
![image](https://user-images.githubusercontent.com/39285147/178196746-f5335637-1b0b-42db-83cb-fd118eb65786.png)
- **Univariate Problem**(ë‹¨ë³€ëŸ‰)
- **Multivariate Problem**(ë‹¤ë³€ëŸ‰)

## Linear regression framework
![image](https://user-images.githubusercontent.com/39285147/178196979-fc670ef5-27ba-4492-b1e6-83199c0b4c75.png)
- **ë‹¨ë³€ëŸ‰ì¸ê°€?**
  - If yes, univariate linear model
- **Predictor Loss í‰ê°€**
  - MSE ìµœì†Œí™”
- **Optimization**
  - Gradient descent algorithm
  - Normal equation

****
# í”¼ë¼ë¯¸í„°(ì„¸íƒ€) ìµœì í™”
![image](https://user-images.githubusercontent.com/39285147/178197289-7fc887bf-df07-435c-88e6-b7170f719e4e.png)
![image](https://user-images.githubusercontent.com/39285147/178197351-fd667f82-cb93-4099-867b-83de0bc62b75.png)
- ì„¸íƒ€ ê°’ì— ë”°ë¼, fitted lineê³¼ ë“±ê³ ì„ ì´ ë³€í•œë‹¤; ë“±ê³ ì„ ì—ì„œ ì†ì‹¤ í•¨ìˆ˜(J)ê°€ ê°€ì¥ **ìµœì†Œ**ê°€ ë˜ëŠ” ì§€ì ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ.
  - ìµœì í™” í”¼ë¼ë¯¸í„°ëŠ” cost functionì„ ê°€ì¥ ìµœì†Œí™” í•˜ëŠ” ê²ƒì— ëª©í‘œê°€ ìˆë‹¤.

![image](https://user-images.githubusercontent.com/39285147/178197438-e087d643-4d00-418f-9d55-0f245fca7ca7.png)
![image](https://user-images.githubusercontent.com/39285147/178197453-f78b90b1-1cda-4a17-bda1-8aac60f1bec6.png)
- í”¼ë¼ë¯¸í„°(ì„¸íƒ€) ê°’ì„ ì¡°ì •í•˜ë©° ê°€ì¥ fitì´ ì˜ ë˜ì—ˆì„ ë•Œ ë“±ê³ ì„ ì˜ ì •ì¤‘ì•™ì— ìµœì†Œ ì§€ì ì— ë„ë‹¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

## í”¼ë¼ë¯¸í„°-ì…ë ¥í”¼ì²˜ì˜ ê´€ê³„
![image](https://user-images.githubusercontent.com/39285147/178197965-dddabfee-38bb-4b38-89a4-2f1103915f90.png)

í”¼ë¼ë¯¸í„°(= ê°€ì¤‘ì¹˜)ëŠ” ì…ë ¥ í”¼ì²˜ê°€ ìµœì¢… ì¶œë ¥ì— ë¼ì¹˜ëŠ” ì˜í–¥ë ¥ì„ ì¡°ì ˆí•œë‹¤.
- **score*(=ëª¨ë¸ì¶œë ¥): ![image](https://user-images.githubusercontent.com/39285147/178202928-b38b1b04-f842-4ac1-8053-dfc9791dda50.png)
- **MSE*: ![image](https://user-images.githubusercontent.com/39285147/178202939-068fed18-542f-4e13-9dc3-430b244c81ee.png)

## 1. Getting a solution ğœ½: *Normal Equation (Least Square)*
![image](https://user-images.githubusercontent.com/39285147/178198986-a37ff222-2855-4be6-8692-cea698ad4545.png)
![image](https://user-images.githubusercontent.com/39285147/178199510-7833b730-c9b1-47d9-9460-6081fb205534.png)
<details markdown="1">
<summary>ìœ ë„ê³¼ì •(ì ‘ê¸°/í¼ì¹˜ê¸°)</summary>

![image](https://user-images.githubusercontent.com/39285147/178199284-1f7c237b-2917-4c42-a3e6-be51920e63af.png)

</details>

- **Normal Equation*: ë„¤ëª¨ë°•ìŠ¤ ë°©ì •ì‹
- **Least Square*: ì¶”ë¡  ê³¼ì •
  - í”¼ë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ ìˆ˜ì‹ì˜ ë¯¸ë¶„ê°’ì´ 0ì´ ë˜ëŠ” ì§€ì (= ìµœì†Œ ì†ì‹¤)ì˜ í”¼ë¼ë¯¸í„° ê°’ì„ êµ¬í•˜ëŠ” ë°©ë²•
  - Assuming that ğ‘¬ is **continuous, differentiable, and convex**

### Normal Equation í•œê³„ì 
- **ë°ì´í„° ìƒ˜í”Œ ìˆ«ìê°€ ëŠ˜ì–´ë‚˜ëŠ” ê²½ìš° ë¹„íš¨ìœ¨ì ì´ë‹¤.**
  - N(ìƒ˜í”Œ ê°œìˆ˜)ê°€ ëŠ˜ì–´ë‚˜ë©´ ì—­í•¨ìˆ˜ ì—°ì‚° ê³¼ì •ì´ ë§¤ìš° ë³µì¡í•´ì§€ê¸° ë•Œë¬¸ì´ë‹¤.
- **ì—­í–‰ë ¬ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°**
  - *Iterative algorithm (Gradient descent)* ë¡œ í•´ê²°

## 2. Getting a solution ğœ½: Gradient descent
![image](https://user-images.githubusercontent.com/39285147/178201137-419c43bf-b1bb-46f2-be40-72bc3545b194.png)

Error surfaceì—ì„œ ìµœì†Œì˜ ì—ëŸ¬ í¬ì¸íŠ¸(*gradient = 0*)ë¥¼ ì°¾ì•„ê°€ëŠ” ê³¼ì •
- Gradient(í•¨ìˆ˜ ë³€í™”ë„)ê°€ ê°€ì¥ í° ë°©í–¥ìœ¼ë¡œ ì´ë™ (ì‚° ì •ìƒì—ì„œ ê°€ì¥ ë¹ ë¥´ê²Œ í•˜ì‚°í•˜ë ¤ë©´ ê°€ì¥ í° í­ìœ¼ë¡œ ë‚´ë ¤ì˜¤ëŠ” ê²ƒê³¼ ê°™ì€ ì´ì¹˜)

## Gradient descent algorithm
![image](https://user-images.githubusercontent.com/39285147/178201002-c7ddd4cb-91d9-474e-9b6b-5d5160154221.png)

ì´ˆê¸° í”¼ë¼ë¯¸í„°ì—ì„œ ì‹œì‘í•˜ì—¬ ëª©ì í•¨ìˆ˜(J)ê°€ ìˆ˜ë ´í•  ë•Œê¹Œì§€ Iterativeí•˜ê²Œ í”¼ë¼ë¯¸í„°ë¥¼ ë°”ê¿”ê°€ë©´ì„œ ìµœì  í”¼ë¼ë¯¸í„°ë¥¼ ì°¾ëŠ”ë‹¤.
- ğ›¼ â†“: ìµœì  í”¼ë¼ë¯¸í„° ì°¾ëŠ” ê³¼ì • ì˜¤ë˜ ê±¸ë¦¼
- ğ›¼ â†‘: ìµœì  í”¼ë¼ë¯¸í„°(gradient = 0) ë†“ì¹  ê°€ëŠ¥ì„± å¤š 

#### Formular
![image](https://user-images.githubusercontent.com/39285147/178201318-f613c2e7-318b-4f74-b3b5-e160c2bf7b01.png)

<details markdown="1">
<summary>í”¼ë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ê³¼ì •(ì ‘ê¸°/í¼ì¹˜ê¸°)</summary>

![image](https://user-images.githubusercontent.com/39285147/178202131-0583c718-48a0-4cbf-b112-68b4c0ce4ce0.png)
![image](https://user-images.githubusercontent.com/39285147/178202146-5409a272-42a9-49a5-80e7-8711bc189ff8.png)

</details>

- *Hyper parameter*: ì‚¬ì „ì— ì„¤ì •ëœ ê°’ë“¤(i.e., ğ›¼)ë¡œ í•­ìƒ ì–‘ìˆ˜ì´ë‹¤.
- *Learnable parameter*: GDë¥¼ í†µí•´ í•™ìŠµí•˜ê³ ì í•˜ëŠ” ê²ƒ(i.e., í”¼ë¼ë¯¸í„°)

### Greedy algorithm
Gradient descent algorithmì—ì„œ ê²½ìš°ì— ë”°ë¼ Local optimumì— ë„ë‹¬í•  ê°€ëŠ¥ì„± ì¡´ì¬
- **Local optimum*
- **Global optimum*

## Gradient descent algorithm vs. Normal equation
![image](https://user-images.githubusercontent.com/39285147/178202658-345986db-2484-42e5-be37-c63ed9993736.png)

### Gradient descent í•œê³„
![image](https://user-images.githubusercontent.com/39285147/178202611-07ed6ee4-54ce-49b2-8d60-6f15d75dfff2.png)
1. Local minima
2. Saddle points

### Gradient descent í•´ê²°
4. Stochastic gradient descent(SGD)
5. Mini batch

****
# Quiz
![image](https://user-images.githubusercontent.com/39285147/178202712-138468c8-3593-452e-8b5d-dce64e2d6656.png)
