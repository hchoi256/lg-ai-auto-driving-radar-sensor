
****
### Terms
- Supervised learning
- Explainable AI (XAI)
  - Explainability / Interpretability
  - Taxonomy of XAI Methods
    - Local vs. Global
    - White box vs. Black box
    - Intrinsic vs. Post hoc
    - Model specific vs. Model agnostic
  - Simple Gradient method
  - SmoothGrad

# Supervised (Deep) Learning
![image](https://user-images.githubusercontent.com/39285147/179156118-6b857604-efbd-411c-afa1-0b3559a4329c.png)

Supervised (deep) learning has made a huge progress!
- Image classification, speech recognition, machine translation, etc.

## Limitation of Supervised Learning: Deep learning models are **EXTREMELY** complex
ëŒ€ìš©ëŸ‰ í•™ìŠµ ë°ì´í„°ë¡œ ë¶€í„° í•™ìŠµí•˜ëŠ” ëª¨ë¸ êµ¬ì¡°ê°€ ì ì  ë” ë³µì¡í•´ì§€ê³  ì´í•´í•˜ê¸° ì–´ë ¤ì›Œì§.

### 1. End to end learning becomes a black box!
![image](https://user-images.githubusercontent.com/39285147/179186432-74ff479c-0603-4c12-95d6-0bf6f41187d5.png)

> End-to-end
>> ë”¥ëŸ¬ë‹ì€ 'ì¢…ë‹¨ê°„ ê¸°ê³„í•™ìŠµ(end-to-end deep learning)' ì´ë¼ê³ ë„ ë¶ˆë¦°ë‹¤. ì—¬ê¸°ì„œ 'ì¢…ë‹¨ê°„' ì€ ì²˜ìŒë¶€í„° ëê¹Œì§€ë¼ëŠ” ì˜ë¯¸ë¡œ, ì…ë ¥ì—ì„œ ì¶œë ¥ê¹Œì§€ 'íŒŒì´í”„ë¼ì¸ ë„¤íŠ¸ì›Œí¬' ì—†ì´ í•œ ë²ˆì— ì²˜ë¦¬í•œë‹¤ëŠ” ëœ»ì´ë‹¤.

### 2. Problem happens when models applied to make critical decisions
![image](https://user-images.githubusercontent.com/39285147/179156427-a4ecf10d-3ef4-4175-87d3-e1e4fe51a54b.png)

e.g , self driving cars, medical diagnosis, loan approval, AI interview, etc.

### 3. Deep learning models can be biased!

## í•´ê²°ì 
We need to **Explainable AI (XAI)** to detect the bias!

# Explainable AI (XAI)
ëª¨ë¸ì´ ì™œ ì´ë ‡ê²Œ ì¸ì¢…ê³¼ ê´€ë ¨í•˜ì—¬ ì˜ëª»ëœ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‚´ì—ˆê³ , ì´ëŸ¬í•œ í‰í–¥ì„± ë°”ì´ì–´ìŠ¤ë¥¼ ê³ ì¹˜ê¸° ìœ„í•´ì„œ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ë“±ì„ ì•Œì•„ë‚´ê¸° ìœ„í•´ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ì„¤ëª… ê°€ëŠ¥í•œ ì¸ê³µì§€ëŠ¥ì´ë‹¤.

ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ë´„ìœ¼ë¡œì¨ ë„ë©”ì¸ì—ì„œ ì˜¤ë¥˜/ë¬¸ì œë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•œë‹¤.

## Reliability & Robustness
[*Pascal VOC 2007 classification*]
![image](https://user-images.githubusercontent.com/39285147/179186982-41db7a02-a5ea-435f-a0a6-ae2b536f53ed.png)

*Pascal*: ì´ë¯¸ì§€ ë¶„ë¥˜ ì—°êµ¬ë¡œ ì“°ì¸ ê¸°ë²•ìœ¼ë¡œ, ì´ë¯¸ì§€ì˜ ì–´ëŠ ë¶€ë¶„ì„ ë³´ê³  classë¥¼ íŒë³„í•˜ì˜€ëŠ”ì§€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œí•œë‹¤.

**XAI ê¸°ë²•**ì€ Pascal ì‹¤í—˜ì´ ì´ë¯¸ì§€ì— í¬í•¨ëœ ì›Œí„°ë§ˆí¬ë¡œ classë¥¼ ë¶„ë¥˜í•˜ëŠ” ì˜¤ë¥˜ë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë¸/ë°ì´í„°ì…‹ì˜ ì˜¤ë¥˜ë¥¼ ìƒ‰ì¶œí•œë‹¤.

## Fairness COMPAS crime prediction (í¸í–¥ì„±)
[*COMPAS*]
![image](https://user-images.githubusercontent.com/39285147/179187567-70d4b6fa-4c3f-4913-8850-559ba7637968.png)

*COMPAS*: ì–´ë–¤ ë²”ì£„ìë¥¼ í’€ì–´ì¤¬ì„ ë•Œ, ê·¸ ì‚¬ëŒì´ ë‹¤ì‹œ ë²”ì£„ë¥¼ ì €ì§ˆëŸ¬ì„œ ê°ì˜¥ìœ¼ë¡œ ëŒì•„ì˜¬ í™•ë¥ ë¥¼ ë„ì¶œí•´ë‚¸ë‹¤.

*XAI ê¸°ë²•*ì€ COMPASê°€ False Positive(í‘ì¸ì´ ë²”ì£„ë¥¼ ì €ì§€ë¥´ì§€ ì•Šì•˜ëŠ”ë°ë„ ë‚˜ì¤‘ì— ì¬ë²”í•  ê²ƒì´ë¼ê³  ì˜ˆì¸¡) í˜¹ì€ False Negative(ë°±ì¸ì´ ë²”ì£„ë¥¼ ì €ì§ˆë €ëŠ”ë°ë„ ë‚˜ì¤‘ì— ë²”ì£„ë¥¼ ì €ì§€ë¥´ì§€ ì•Šì„ ê²ƒì´ë‹¤)ë¼ëŠ” ì˜ëª»ëœ ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë°œê²¬í•œë‹¤.

## Critical systems
- Self-driving car (ìë™ì°¨ ì‚¬ê³  ì›ì¸ íŒë‹¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤)
- COVID19 classification (ì™œ ì•Œê³ ë¦¬ì¦˜ì´ ê·¸ëŸ° ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ëƒˆëŠ”ì§€ ì„¤ëª…í•˜ëŠ” ê²ƒì€ ì‹ ë¢° ì—¬ë¶€ë¥¼ ê²°ì •í•œë‹¤)

# Explainability / Interpretability?
### Interpretability
â€“ Interpretability is the degree to which a human can understand the cause of a decision 
â€“ Interpretability is the degree to which a human can consistently predict the model's results
â€“ An explanation is the answer to why question
â€“ Or in dictionary

### Explainability
- ì‚¬ëŒì´ ëª¨ë¸ì„ ì“¸ ë•Œ ê·¸ ë™ì‘ì„ ì´í•´í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê¸°ê³„ í•™ìŠµ ê¸°ìˆ 

# Taxonomy of XAI Methods
### Local vs. Global
- **Local**: Describes an individual prediction (ì£¼ì–´ì§„ íŠ¹ì • ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì„¤ëª…)
- **Global**: Describes entire model behavior (ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ëª¨ë¸ì˜ ì „ë°˜ì ì¸ í–‰ë™ì„ ì„¤ëª…)

### White box vs. Black box
- **White box**: Explainer can access the inside of model (ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ì •í™•í•˜ê²Œ ì•Œê³  ìˆëŠ” ìƒí™©ì—ì„œ ì„¤ëª…ì„ ì‹œë„)
- **Black box**: Explainer can access only the output (ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬ì¡°ëŠ” ëª¨ë¥¸ì±„, ë‹¨ìˆœíˆ ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ë§Œ ê°€ì§€ê³  ì„¤ëª…ì„ ì‹œë„)

## Intrinsic vs. Post hoc
- **Intrinsic**: Restricts the model complexity before training (ëª¨ë¸ì˜ ë³µì¡ë„ í›ˆë ¨ ì´ì „ë¶€í„°, ì„¤ëª…ì— ìš©ì´í•œ ì œì•ˆì„ í•œ ë’¤ í•™ìŠµì„ ì‹œí‚¨ ëª¨ë¸ì„ ê°€ì§€ê³  ì„¤ëª…)
- **Post hoc**: Applies after the ML model is trained (ì„ì˜ ëª¨ë¸ í›ˆë ¨ ì´í›„ ì´ ë°©ë²•ì„ ì ìš©í•´ì„œ ê·¸ ëª¨ë¸ì˜ í–‰ë™ì„ ì„¤ëª…)

### Model specific vs. Model agnostic
- **Model specific**: Some methods restricted to specific model classes (e.g., CAM requires global average pooling) (íŠ¹ì • ëª¨ë¸ êµ¬ì¡°ì—ë§Œ ì ìš© ê°€ëŠ¥)
- **Model agnostic**: Some methods can be used for any model (ëª¨ë¸ êµ¬ì¡°ì™€ ê´€í•˜ê²Œ ì–´ëŠ ëª¨ë¸ì—ë„ í•­ì‹œ ì ìš©)

## Linear model, Simple Decision Tree
![image](https://user-images.githubusercontent.com/39285147/179189844-ad8ff3bb-257d-4bf6-92cc-7d8fe19f0ffe.png)

**Global, White box, Intrinsic, Model specific**

## Grad CAM
![image](https://user-images.githubusercontent.com/39285147/179190062-608a96d2-edbb-4667-a870-48a5ebff6e30.png)

**Local, White box, Post hoc, Model agnostic*


## Outline
![image](https://user-images.githubusercontent.com/39285147/179199879-6ecfd9dc-78ab-4f79-9f5f-e2f50d52091b.png)

**Saliency map-based**
- í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ìƒ˜í”Œì´ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ë©´ ê·¸ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª…ì„ ì´ë¯¸ì§€ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ í•˜ì´ë¼ì´íŠ¸í•´ì„œ ë³´ì—¬ì¤€ë‹¤. 

### Simple Gradient method
![image](https://user-images.githubusercontent.com/39285147/179200145-04b347ae-c680-4eb7-9347-5e6b33c1e343.png)

ì…ë ¥ì— ëŒ€í•œ ëª¨ë¸ì˜ Gradientë¡œ ì„¤ëª…ì„ ì œê³µí•œë‹¤ (ë”¥ëŸ¬ë‹ ëª¨ë¸ Back-Propagationìœ¼ë¡œ ê°„ë‹¨íˆ êµ¬í˜„ ê°€ëŠ¥í•˜ë‹¤).
- Gradient â†‘, í•´ë‹¹ í”½ì…€ì— ì¤‘ìš”ë„ â†‘

#### Examples
![image](https://user-images.githubusercontent.com/39285147/179200476-77a493ae-e38c-41c2-8e6b-ac369eb60a6d.png)

The gradient maps are visualized for the highest scoring class (top 1 class prediction)

### Strength / Weakness
Strength
- Easy to compute (via back propagation)

Weakness
- Becomes noisy (due to shattering gradient (ì¡°ê¸ˆì”© ë³€í™”ê°€ ìˆëŠ” ê°™ì€ ì˜ˆì¸¡ ê²°ê³¼ê°’ì„ ë„ì¶œí•´ë‚´ëŠ” ê° ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ì„¤ëª…ì€ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤)
  - í•´ê²°: **SmoothGrad**

### í•´ê²°: SmoothGrad
![image](https://user-images.githubusercontent.com/39285147/179200889-b6ce5429-4e1f-4cce-83a7-971a24a28850.png)

Noisyí•œ Gradientë“¤ì„ ë§ì´ ì œê±°í•˜ê³  í‰ê· ì ìœ¼ë¡œ ë‚¨ëŠ” Gradientê°€ ë” ê¹¨ë—í•œ ì„¤ëª…ì´ ê°€ëŠ¥í•˜ë‹¤.

A simple method to address the **noisy** gradients
- Add some noise to the input and average!
- Averaging gradients of slightly perturbed input would **smoothen** the interpretation
- Typical heuristics
  - Expectation is approximated with Monte Carlo (around 50 runs)
  - ğœis set to be 10~20% of ğ‘¥ğ‘šğ‘ğ‘¥âˆ’ğ‘¥ğ‘šğ‘–ğ‘›

#### Strength / Weakness
![image](https://user-images.githubusercontent.com/39285147/179201251-8c93b59a-0a4b-48e4-afd2-9ceefebccf16.png)

SmoothGrad seems to work better for *uniform* background

**Strength**
- Clearer interpretation via simple averaging
- Applicable to most sensitive maps

**Weakness**
- Computationally expensive! (Back propagationë§Œí¼ ê³„ì‚° ìˆ˜í–‰í•´ì•¼í•œë‹¤)
